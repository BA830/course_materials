{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e2a5e3",
   "metadata": {},
   "source": [
    "# Course Notes: Business Experiments and Causal Methods\n",
    "\n",
    "## Potential Outcomes\n",
    "\n",
    "### Motivation\n",
    "\n",
    "**Question: Does attending class in person cause a person to get an A grade (vs getting a grade lower than an A)?**\n",
    "\n",
    "This is a causal question, because we are interested in knowing if the treatment, attending class in person, has an effect on the grade.\n",
    "\n",
    "### Intuition\n",
    "\n",
    "We know that some people attend class in person and some log in remotely. We also know what grade each person receives. Suppose that 70\\% of people who attend class in person get an A but 30\\% of people who attend remotely get an A. We can't say that going to class in person *causes* a higher grade. The reason is that people who go to class in-person may have other characteristics that cause them to get an A. For example, they could be more motivated or they may have more preparation for the class. The difference in characteristics between those who attend class and those who don't is called *selection bias*.\n",
    "\n",
    "The gold standard for causal questions is a randomized clinical trial (RCT), because randomization solves the problem of selection bias.\n",
    "An RCT ensures that, on average, the treatment is independent of the potential outcome.\n",
    "But what is a potential outcome?\n",
    "\n",
    "Suppose that *if* I receive treatment $T$, then I *will* get outcome $Y(T)$.\n",
    "Instead, suppose that *if* I receive treatment $C$, then I *will* get outcome $Y(C)$.\n",
    "My potential outcomes, therefore, are $Y(T)$ and $Y(C)$. Note, these outcome exist in theory. Which outcome I observe depends on which treatment I got in reality. The outcome that I *actually* observe depends on the treatment I receive.\n",
    "\n",
    "Unfortunately, we can only observe one outcome, and so we can only observe one potential outcome.\n",
    "This is the *fundamental problem of causal inference*.\n",
    "Because of this, causal inference is a missing data problem.\n",
    "An RCT provides a principled way to perform this imputation, but often we only have observational data.\n",
    "In this case, the potential outcome framework is necessary because:\n",
    "\n",
    "1. causal inference is subtle\n",
    "2. it ensures we are working with a causal question\n",
    "3. it helps us identify the causal claim\n",
    "\n",
    "### Notation\n",
    "For now, suppose that there are only two treatments, one of which we'll call the treatment (T = 1), and another which we'll call the control (T = 0).\n",
    "We write that\n",
    "\n",
    "\\begin{align*}\n",
    "Y_i(1) &\\text{ is the potential outcome for person } i \\text{ under treatment} \\\\\n",
    "Y_i(0) &\\text{ is the potential outcome for person } i \\text{ under no treatment}\n",
    "\\end{align*}\n",
    "\n",
    "Note that $i$ could also refer to a \\textit{unit} when we are not working with people or patients.\n",
    "In our example above, attending class in-person refers to treatment $(1)$, whereas not attending class in-person corresponds to no treatment $(0)$.\n",
    "This notation will allow us to mathematically formulate our assumptions, as well identify our causal question and perform our analysis.\n",
    "\n",
    "### Example\n",
    "\n",
    "Back to our original question, suppose we know the potential outcomes of six people:\n",
    "\n",
    "#### Table 1\n",
    "\n",
    "| Person | $Y_i(1)$ | $Y_i(0)$ | $Y_i(1) - Y_i(0)$|\n",
    "|:------:|:--------:|:--------:|:----------------:|\n",
    "|    1   |     1    |     1    |       0          |\n",
    "|    2   |     1    |     1    |       0          |\n",
    "|    3   |     1    |     0    |       1          |\n",
    "|    4   |     0    |     0    |       0          |\n",
    "|    5   |     0    |     1    |       -1         |\n",
    "|    6   |     0    |     0    |       0          |\n",
    "\n",
    "where $Y_i(1) = 1$ is getting an A if person $i$ attends in-person and $Y_i(1) = 0$ is getting less than an A if person $i$ attends in-person.\n",
    "Similarly, $Y_i(0) = 1$ is getting an A if person $i$ does not attend and $Y_i(0) = 0$ is getting less than an A if person $i$ does not attend.\n",
    "Given the above, $Y_i(1) - Y_i(0)$ is the effect of attending class in person on the grade of person $i$.\n",
    "\n",
    "In this case, we can see what the effect would be for each person.\n",
    "In particular, persons 1 and 2 will get an A no matter their treatment; person 3 will be helped by treatment, i.e will get an A if they attend and will not get an A if they don't attend. Persons 4 and 6 will always get less than an A no matter their treatment; person 5 will be hurt by treatment.\n",
    "\n",
    "In reality, we will never see both potential outcomes for each person.\n",
    "Instead, we will observe something like this:\n",
    "\n",
    "#### Table 2\n",
    "\n",
    "| Person | $T_i$ | $Y_i$ |\n",
    "|:------:|:-----:|:-----:|\n",
    "|    1   |   1   |   1   |\n",
    "|    2   |   1   |   1   |\n",
    "|    3   |   1   |   1   |\n",
    "|    4   |   0   |   0   |\n",
    "|    5   |   0   |   1   |\n",
    "|    6   |   0   |   0   |\n",
    "\n",
    "\n",
    "where $A_i$ is the treatment for person $i$ and $Y_i$ is the observed outcome for person $i$. \n",
    "Thus, persons 1, 2, and 3 attend class in-person, whereas persons 4, 5, and 6 do not.\n",
    "And persons 1, 2, 3, and 5 get an A, whereas persons 4 and 6 do not.\n",
    "Using this observed data, we can partially fill out our potential outcomes table:\n",
    "\n",
    "#### Table 3\n",
    "\n",
    "| Person | $T_i$ | $Y_i$ | $Y_i(1)$ | $Y_i(0)$ | $Y_i(1) - Y_i(0)$ |\n",
    "|:------:|:-----:|:-----:|:--------:|:--------:|:-----------------:|\n",
    "| 1 | 1 | 1 | 1   | ??? | ??? |\n",
    "| 2 | 1 | 1 | 1   | ??? | ??? |\n",
    "| 3 | 1 | 1 | 1   | ??? | ??? |\n",
    "| 4 | 0 | 0 | ??? | 0   | ??? |\n",
    "| 5 | 0 | 1 | ??? | 1   | ??? |\n",
    "| 6 | 0 | 0 | ??? | 0   | ??? |\n",
    "\n",
    "The goal of causal inference is to fill in these missing values so that we can understand the effect of attending class on grades.\n",
    "In the case of an RCT, we can estimate $Y_i(1)$ just through the outcomes of those treated, because randomization ensures the outcome is independent of the treatment.\n",
    "Likewise for estimating $Y_i(0)$.\n",
    "For observational studies, we will attempt to emulate a RCT, which will require us to make more assumptions.\n",
    "\n",
    "Note that because of the fundamental problem of causal inference, we will never be able to know the treatment effects on an individual level.\n",
    "That is, unlike Table 1, where we know the treatment effects for each person, Table 3 will only ever allow us to estimate average treatment effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f33795",
   "metadata": {},
   "source": [
    "## Average Treatment Effects\n",
    "\n",
    "### Intuition\n",
    "\n",
    "We've already established that we cannot know an individual's treatment effect. The reason is that we can't observe their outcome both when they do and do not get treated.[^1] What we can try to learn, however, is the average treatment effect in the sample of people we're considering.\n",
    "\n",
    "Suppose we know the average potential outcome in the treated group and the average potential outcome in the control group. The difference in the average potential outcomes is the average treatment effect. Organizations often care about the average treatment effect. Let's say we are a political campaign and that we want to raise money. We have a choice of whether to send email A or email B. To determine which email to send, we need to know whether we raise more money when we send email A or B. In this case, we care about getting the highest average treatment effect. Note that it could be the case that for some individuals A causes more donations than B (and vice versa). However, the campaign cares about the sum of the donations.[^2]\n",
    "\n",
    "Of course, we can't know the potential outcomes, we only know the realized outcomes. One thing we can do is compare realized outcomes for those who get email A with those who get email B. Typically, we'd be worried about selection bias. However, if we randomized who got email A and B, we can compare the difference in average realized outcomes to get an estimate of the average treatment effect. What do we mean by an estimate, think of it as the best guess, given the available data, that we have about the average treatment effect. An estimator is a procedure for getting the estimate. In this case, the estimator consists of taking the average donations of all those who got email A and subtracting the average donations of all those who got email B.\n",
    "\n",
    "We now describe the above in more detail.\n",
    "\n",
    "[^1]: You may wonder, can't a person get treated one day and not treated the next? This is a great question. We have to be very precise with what we mean by a potential outcome. We can't guarantee that a person's potential outcomes one day are the same as their potential outcomes the next. For example, suppose that you had a lot of sleep one day but not a lot of sleep the next. On the day when you had little sleep, going to lecture in-person may not have mattered as much as on a day with a lot of sleep. Therefore, the potential outcome is always defined with respect to the specific time at which a person gets treatment.\n",
    "\n",
    "[^2]: This would be different if the campaign could target emails to different users. We will discuss this example later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c12e06",
   "metadata": {},
   "source": [
    "*Expectation* is the weighted average of all possible outcomes, where the weights are the probabilities with which the event happens.\n",
    "\n",
    "For example, suppose we roll a die and $X$ is a random variable describing the value of the roll.\n",
    "For a fair die, we have $f_X(x) = 1/6$ for all $x \\in \\Omega = \\{1, 2, \\ldots, 6\\}$. That is, each of the 6 values is equally likely.\n",
    "Then the expected value for $X$ is\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[X] &= \\sum_{x=1}^6 x \\cdot \\mathbb{P}(X = x) \\\\\n",
    "&= 1 \\cdot 1/6 + 2 \\cdot 1/6 + \\cdots + 6 \\cdot 1/6 \\\\\n",
    "&= 3.5\n",
    "\\end{align*}\n",
    "\n",
    "Therefore, the expectation of $X$ is $3.5$.\n",
    "It should be clear that even though this is the expected value of our die, it is not possible to actually obtain $3.5$.\n",
    "So, while the expectation describes the \"typical\" outcome, it need not be observable.\n",
    "\n",
    "Here are a few properties of expectation:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[a] &= a & \\text{expectation of a constant} \\\\\n",
    "\\mathbb{E}[aX + bY] &= a\\mathbb{E}[X] + b\\mathbb{E}[Y] & \\text{linearity of expectation}\n",
    "\\end{align*}\n",
    "\n",
    "Another important concept is conditional expectation.\n",
    "The *conditional expectation* of a random variable (RV) is its expectation given certain constraints (conditions) on the random variable.\n",
    "\n",
    "For example, let $X$ be the RV above describing the die.\n",
    "What is the expectation of $X$ given that we roll an even number?\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[X | X \\text{ is even}] &= 2\\cdot \\mathbb{P}(X = 2 | X \\text{ is even}) + 4\\cdot \\mathbb{P}(X = 4 | X \\text{ is even}) + 6\\cdot \\mathbb{P}(X = 6 | X \\text{ is even}) \\\\\n",
    "&= 2\\cdot 1/3 + 4\\cdot 1/3 + 6\\cdot 1/3 \\\\\n",
    "&= 4\n",
    "\\end{align*}\n",
    "\n",
    "Note that we use the conditional probabilities to compute the conditional expectation.\n",
    "In this case, we see that the conditional expectation of $X$ given $X$ is even is different than the expectation of $X$.\n",
    "\n",
    "### ATE and ATT\n",
    "\n",
    "Recall that by the fundamental problem of causal inference, we will never be able to infer individual treatment effects.\n",
    "Instead, we can combine our potential outcomes framework with the notion of expectation to define the *average treatment effect* (ATE).\n",
    "$$ATE = \\mathbb{E}[Y_i(1)] - \\mathbb{E}[Y_i(0)]$$\n",
    "In words, the ATE is the difference between the expected outcomes under treatment versus no treatment.\n",
    "In the case of randomized treatment, we can estimate the ATE as the difference in empirical means of the treated versus untreated, since randomization ensures the treatment is independent of the potential outcome. Here is the formal math. Let $T_{i}$ be the random variable that represents whether individual, i, is treated. \n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[Y_i(1) | T_{i} = 1] &= \\mathbb{E}[Y_i(1)] = \\mathbb{E}[Y_i(1) | T_{i} = 0] \\\\\n",
    "\\mathbb{E}[Y_i(0) | T_{i} = 1] &= \\mathbb{E}[Y_i(0)] = \\mathbb{E}[Y_i(0) | T_{i} = 0]\n",
    "\\end{align*}\n",
    "\n",
    "Hence, in a randomized setting, we have\n",
    "$$ATE = \\mathbb{E}[Y_i(1) | T_i = 1] - \\mathbb{E}[Y_i(0) | T_i = 0]$$\n",
    "We can estimate ATE using our standard estimator for means:\n",
    "$$\\widehat{ATE} = \\frac{1}{m}\\sum_{i=1}^N Y_i \\cdot 1_{T_i = 1} - \\frac{1}{N-m}\\sum_{i=1}^N Y_i \\cdot 1_{T_i = 0}$$\n",
    "where $N$ is the number of people in our study, $m < N$ is the number of treated persons, and $1_{T = a}$ is the treatment indicator, i.e\n",
    "$$1_{T = a} = \\begin{cases}\n",
    "1 & \\text{if } T = a \\\\\n",
    "0 & \\text{if } T \\neq a\n",
    "\\end{cases}$$\n",
    "This estimator has the desirable property that it is unbiased.\n",
    "For this to even make sense, we have to recognize that the estimator is a random variable, since the estimator is a function of the data, which is itself random.\n",
    "Then, the estimator is unbiased if its expectation is equal to the parameter it is estimating.\n",
    "In this case, that means $\\mathbb{E}[\\widehat{ATE}] = ATE$.\n",
    "\n",
    "### Example\n",
    "\n",
    "Let's return to our example data in Table 2.\n",
    "Suppose the treatment were randomized.\n",
    "Here, we estimate the ATE:\n",
    "\n",
    "\\begin{align*}\n",
    "\\widehat{ATE} &= \\frac{1}{3}\\sum_{i=1}^6 Y_i 1_{T_i = 1} - \\frac{1}{3}\\sum_{i=1}^6 Y_i 1_{T_i = 0} \\\\\n",
    "&= \\frac{1}{3} \\cdot 3 - \\frac{1}{3} \\cdot 1 \\\\\n",
    "&= 1 - \\frac{1}{3} \\\\\n",
    "&= \\frac{2}{3}\n",
    "\\end{align*}\n",
    "\n",
    "Since $\\widehat{ATE} > 0$, we would interpret the treatment to be effective. Note that we put a $\\widehat{hat}$ on a theoretical quantity to denote that something is an estimate of that quantity.\n",
    "\n",
    "Here is code to do this in `Python`: (Please note we will use [`Pandas`](https://pandas.pydata.org/docs/index.html) to handle data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02afd269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>T</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  T  Y  Y0  Y1\n",
       "0       1  1  1   1   1\n",
       "1       2  1  1   1   1\n",
       "2       3  1  0   1   0\n",
       "3       4  0  0   0   0\n",
       "4       5  0  1   0   1\n",
       "5       6  0  0   0   0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the module pandas to handle data frames\n",
    "import pandas as pd \n",
    "\n",
    "# Create a DataFrame representing the data\n",
    "data_po = {'person': [1, 2, 3, 4, 5, 6],\n",
    "        'T': [1, 1, 1, 0, 0, 0],\n",
    "        'Y': [1, 1, 0, 0, 1, 0],\n",
    "        'Y0': [1, 1, 1, 0, 0, 0],\n",
    "        'Y1': [1, 1, 0, 0, 1, 0]}\n",
    "\n",
    "data_po = pd.DataFrame(data_po)\n",
    "\n",
    "# Return the DataFrame\n",
    "data_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3449530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the ATE estimate\n",
    "ate = data_po.loc[data_po['T'] == 1, 'Y'].mean() - data_po.loc[data_po['T'] == 0, 'Y'].mean()\n",
    "\n",
    "ate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e284c685",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "- `df.loc[df['T'] == 1, 'Y']` selects the values of 'Y' where 'T' is equal to 1.\n",
    "- `df.loc[df['T'] == 0, 'Y']` selects the values of 'Y' where 'T' is equal to 0.\n",
    "- `.mean()` calculates the mean of the selected values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88661d81",
   "metadata": {},
   "source": [
    "However, this is only a *point estimate* of ATE.\n",
    "\n",
    "We should be wary of our conclusion, which only involved six individuals. For example, suppose that our randomization resulted in a different set of individuals being treated. In that case, our estimate of the ATE would be different. The bigger the number of individuals in our experiment, the less it matters what specific randomization occured. \n",
    "\n",
    "Next, we will see how to perform uncertainty quantification to assess how confident we should be about our estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66662e0e",
   "metadata": {},
   "source": [
    "## Uncertainty Quantification\n",
    "\n",
    "Suppose we flip a coin and it lands on heads.\n",
    "Do we believe the coin is biased in favor of heads?\n",
    "What if we flip it again and it lands on heads?\n",
    "Is it biased now?\n",
    "Intuitively, we believe that flipping a coin and landing on heads 92 times in a row is much more *evidence* towards bias than just twice.\n",
    "But we can actually quantify how (un)likely such scenarios are, which allows us to perform *uncertainty quantification*.\n",
    "Then, we can directly compare our observed results to the variation we would expect due to chance alone.\n",
    "\n",
    "Below, we will discuss the following concents: variance and standard deviation, confidence intervals, and p-values. There are Python functions that can calculate these automatically, which we will discuss after explaining the concepts.\n",
    "\n",
    "\n",
    "### Variance and Standard Deviation\n",
    "\n",
    "The *variance* of a RV $X$ is its second central moment.\n",
    "It is defined as the expectation of the squared difference from the mean $\\mu = \\mathbb{E}[X]$:\n",
    "$$\\sigma^2 = \\text{Var}(X) = \\mathbb{E}\\big[(X - \\mu)^2\\big]$$\n",
    "Intuitively, variance measures the spread of a RV about its mean.\n",
    "\n",
    "\n",
    "Note that if a RV is described by a given unit of measurement, its variance is described by the squared unit.\n",
    "For this reason, it is common to present the square root of the variance, which is known as the *standard deviation*:\n",
    "$$\\sigma = \\sigma(X) = \\sqrt{\\text{Var}(X)}$$\n",
    "\n",
    "If we know the distribution of our RV, or we have access to the whole population, then we can compute the *population* variance and standard deviation.\n",
    "More often, we are given a sample $X_1, \\ldots, X_n \\sim X$, and we can only compute a *sample* variance or standard deviation similar to how we estimate the mean using the sample mean: \n",
    "$$\\bar{X} = \\frac{1}{n}\\sum_{i=1}^n X_i$$\n",
    "In this case, our sample variance and standard deviation are computed as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "s^2 &= \\frac{1}{n-1}\\sum_{i=1}^n\\big(X_i - \\bar{X}\\big)^2 \\\\\n",
    "s &= \\sqrt{s^2} = \\sqrt{\\frac{1}{n-1}\\sum_{i=1}^n\\big(X_i - \\bar{X}\\big)^2}\n",
    "\\end{align*}\n",
    "\n",
    "Note that we use the Latin $s$ to denote the sample estimators rather than the Greek $\\sigma$.\n",
    "This is similar to how we use $\\bar{X}$ for the sample mean rather than $\\mu$.\n",
    "Also, note that in the calculation of sample variance, we divide by $n-1$ rather than $n$, as might be expected for an average.\n",
    "This is so that our estimator is unbiased, but, for large $n$, the values are similar to dividing by $n$, which is what you do for the maximum likelihood estimator.\n",
    "\n",
    "\n",
    "For large samples, calculating sample variance and standard deviation can be tedious.\n",
    "However, the `Python` module `Numpy` has built-in the functions `numpy.var` and `numpy.std` that make these calculations easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54fe1383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_bar</th>\n",
       "      <th>X_var</th>\n",
       "      <th>X_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.062594</td>\n",
       "      <td>0.888054</td>\n",
       "      <td>0.942366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      X_bar     X_var      X_sd\n",
       "0 -0.062594  0.888054  0.942366"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(472)  # set seed for reproducible results\n",
    "\n",
    "n = 50\n",
    "\n",
    "# X is a vector of 50 random numbers.\n",
    "X = np.random.randn(n)  # sample X_1, ..., X_50 ~ Z = N(0, 1)\n",
    "\n",
    "X_bar = np.mean(X)  # sample mean\n",
    "X_var = np.sum((X - X_bar)**2) / (n - 1)  # sample variance\n",
    "X_sd = np.sqrt(X_var)  # sample standard deviation\n",
    "\n",
    "# Create a DataFrame to display the results\n",
    "result_df = pd.DataFrame({\n",
    "    'X_bar': [X_bar],\n",
    "    'X_var': [X_var],\n",
    "    'X_sd': [X_sd]\n",
    "})\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "149a2270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_var matches var(X): True\n",
      "X_sd matches sd(X): True\n"
     ]
    }
   ],
   "source": [
    "# Check if X_var matches var(X) and X_sd matches sd(X)\n",
    "var_match = X_var == np.var(X, ddof=1)  # ddof=1 for sample variance\n",
    "sd_match = X_sd == np.std(X, ddof=1)    # ddof=1 for sample standard deviation\n",
    "\n",
    "print(f\"X_var matches var(X): {var_match}\")\n",
    "print(f\"X_sd matches sd(X): {sd_match}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530e072",
   "metadata": {},
   "source": [
    "### Confidence Intervals\n",
    "\n",
    "One of the most important uses of variance and standard deviation is for building confidence intervals.\n",
    "In our example above, we calculate that $\\bar{X} \\approx -0.06$ even though we know that $\\mu = 0$.\n",
    "We can build an interval around our sample mean, which is still our best guess for what $\\mu$ is based on our sample, that incorporates the uncertainty that we expect from a single sample of size $n = 50$.\n",
    "From the *Central Limit Theorem*, we know that the sampling distribution for $\\bar{X}$ is normally distributed about $\\mu$.\n",
    "It follows that a confidence interval for $\\bar{X}$ is\n",
    "$$\\Big(\\bar{X} - z^*\\frac{s}{\\sqrt{n}}, \\bar{X} + z^*\\frac{s}{\\sqrt{n}}\\Big)$$\n",
    "where $z^*$ is a *critical value* that depends on our desired level of confidence, usually expressed as $1 - \\alpha$.\n",
    "Typically, we use the values of $z^*$ given in Table 4.\n",
    "\n",
    "#### Table 4\n",
    "\n",
    "$\\alpha$ | Confidence | $z^*$\n",
    "--- | --- | ---\n",
    ".01 | .99 | 2.576\n",
    ".05 | .95 | 1.96\n",
    ".1 | .90 | 1.645\n",
    "\n",
    "In `Python`, we can use the `scipy.stats.norm` module to compute quantiles of the normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f6a9615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confidence</th>\n",
       "      <th>z_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>2.575829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1.959964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.90</td>\n",
       "      <td>1.644854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Confidence    z_star\n",
       "0        0.95  2.575829\n",
       "1        0.99  1.959964\n",
       "2        0.90  1.644854"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "# note that the probability supplied in norm.ppf is not 1-alpha\n",
    "# but instead 1 - alpha/2 because we have a two-sided conf. int.\n",
    "\n",
    "conf_99 = norm.ppf(0.995)  # conf = 99%\n",
    "conf_95 = norm.ppf(0.975)  # conf = 95%\n",
    "conf_90 = norm.ppf(0.95)   # conf = 90%\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Confidence': [.95, .99, .90],\n",
    "    'z_star': [conf_99, conf_95, conf_90],\n",
    "})\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70166a8c",
   "metadata": {},
   "source": [
    "The interpretation of this procedure is that for repeated samples of size $n$, by computing the confidence interval as above, we will capture the true population mean $100\\times(1 - \\alpha)\\%$ of the time.\n",
    "This does not mean that a given confidence interval has a $100\\times(1 - \\alpha)\\%$ probability of containing the true parameter.\n",
    "\n",
    "In summary, a confidence interval has the following components:\n",
    "\n",
    "1. sample mean $\\bar{X}$\n",
    "2. sample standard deviation $s$\n",
    "3. sample size $n$\n",
    "4. confidence level $1-\\alpha$\n",
    "\n",
    "It is worth noting that, as experimenters, the only things we can control are the sample size $n$ and our desired confidence level $1-\\alpha$.\n",
    "\n",
    "As an example, here is the $95\\%$ confidence interval from our sample using `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "240dae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32379949  0.19861215]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# Confidence interval calculation\n",
    "conf_interval = np.array([\n",
    "    X_bar - norm.ppf(1 - alpha/2) * X_sd / np.sqrt(n),\n",
    "    X_bar + norm.ppf(1 - alpha/2) * X_sd / np.sqrt(n)\n",
    "])\n",
    "\n",
    "print(conf_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f223f9b",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "Instead of computing a confidence interval, we can express the same information through a *hypothesis test*.\n",
    "That is, hypothesis testing is an alternative but equivalent framework to building confidence intervals.\n",
    "The procedure for a hypothesis test is as follows:\n",
    "\n",
    "1. State your null and alternative hypotheses, as well as your desired confidence level\n",
    "2. compute your test statistic\n",
    "3. find the p-value associated with the test statistic\n",
    "4. compare p-value to $\\alpha$\n",
    "5. Note, we will illustrate these steps, but there are Python functions that do 1 - 4 automatically in one line. We discuss these afterward. \n",
    "\n",
    "A hypothesis test is best illustrated with an example.\n",
    "Suppose $\\bar{X}$ from above is actually an estimate for an average treatment effect, $\\widehat{ATE}$.\n",
    "Generally, a null hypothesis represents the status quo, so the null hypothesis is whatever the default position for the context of our experiment.\n",
    "In this case, our null hypothesis is that there is no treatment effect, which we express as\n",
    "$$H_0: ATE = 0$$\n",
    "The alternative hypothesis is that there is an average treatment effect.\n",
    "If we do not know the sign of the effect, then this is a two-tailed test, which we express as\n",
    "$$H_A: ATE \\neq 0$$\n",
    "Note that our hypotheses are in terms of our population parameter rather than our sample estimator.\n",
    "\n",
    "The next step is to compute a test statistic, which is a summary of our data based on the nature of the test.\n",
    "For sample means including average treatment effect, the test when $n$ is large is the $Z$-test with corresponding $Z$-score:\n",
    "$$Z = \\frac{\\bar{X} - \\mu_0}{\\text{SE}}$$\n",
    "where $\\bar{X}$ is our sample mean, $\\mu_0$ is the mean *under the null hypothesis*, and $\\text{SE} = \\frac{\\sigma}{\\sqrt{n}}$ is the standard error.\n",
    "Usually, we have $\\mu_0 = 0$.\n",
    "\n",
    "Once we have the test statistic, we compare it to the sampling distribution under the null, which, for a $Z$-test, is the standard normal distribution $Z = N(0, 1)$.\n",
    "This comparison yields a p-value and if $p < \\alpha$, we *reject* our null hypothesis in favor of the alternative hypothesis.\n",
    "Otherwise, we *fail to reject* our null hypothesis because we do not have enough evidence in support of the alternative hypothesis.\n",
    "There is a lot of misconception about p-values, but suffice to say their interpretation is as subtle as the interpretation for confidence intervals: a p-value is the probability that, if the null hypothesis were true, we would observe something as or more extreme than our actual observed data.\n",
    "\n",
    "Going back to our example, here is how we would perform a test for $\\widehat{ATE} = 0$ using `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4960bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error (SE): 0.1332707243677306\n",
      "Z-score (Z): -0.4696730554496753\n",
      "P-value (p): 0.6385886212553631\n",
      "Do we reject H_0? False\n"
     ]
    }
   ],
   "source": [
    "# Calculate standard error\n",
    "SE = X_sd / np.sqrt(n)\n",
    "\n",
    "# Calculate z-score\n",
    "Z = (X_bar - 0) / SE\n",
    "\n",
    "# Calculate p-value\n",
    "p = 2 * norm.cdf(- np.abs(Z)) # this is a two-sided test\n",
    "\n",
    "# Check if we reject H_0\n",
    "reject = p < alpha  # alpha = 0.05\n",
    "\n",
    "print(f\"Standard Error (SE): {SE}\")\n",
    "print(f\"Z-score (Z): {Z}\")\n",
    "print(f\"P-value (p): {p}\")\n",
    "print(f\"Do we reject H_0? {reject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13216b90",
   "metadata": {},
   "source": [
    "In our example, we see that $p \\approx 0.64 > \\alpha = 0.05$, hence we fail to reject the null hypothesis.\n",
    "This means that we do not have enough evidence to support the hypothesis that there is an average treatment effect.\n",
    "This coincides exactly to the fact that $\\mu_0 = 0$ was contained in our $95\\%$ confidence interval from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9f840e",
   "metadata": {},
   "source": [
    "### Using Python to compute standard errors, confidence intervals, and p-values with one function.\n",
    "\n",
    "The `Python` module `statsmodels.stats.weightstats` has built-in functions for statistical tests. The ttest_ind function calculates the confidence interval and p-value automatically.\n",
    "We will now demonstrate how to compute the treatment effect estimate, confidence interval, and p-value using our table of outcomes `data_po`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3d13c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>T</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person  T  Y  Y0  Y1\n",
       "0       1  1  1   1   1\n",
       "1       2  1  1   1   1\n",
       "2       3  1  0   1   0\n",
       "3       4  0  0   0   0\n",
       "4       5  0  1   0   1\n",
       "5       6  0  0   0   0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall that this is our data:\n",
    "data_po"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a55be751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-score (t): 0.7071067811865475\n",
      "P-value (p): 0.5185185185185183\n",
      "Do we reject H_0? False\n",
      "Confidence Interval: -0.5906195274170887, 1.2572861940837554\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.weightstats import ttest_ind, _tconfint_generic\n",
    "\n",
    "treated_sample = data_po[data_po['T'] == 1]['Y']\n",
    "control_sample = data_po[data_po['T'] == 0]['Y']\n",
    "tstat, pvalue, df = ttest_ind(x1 = treated_sample, x2 = control_sample, alternative = 'two-sided', usevar = 'pooled', value = 0) # df is the degree of freedom\n",
    "reject = pvalue < alpha  # alpha = 0.05\n",
    "\n",
    "print(f\"t-score (t): {tstat}\")\n",
    "print(f\"P-value (p): {pvalue}\")\n",
    "print(f\"Do we reject H_0? {reject}\")\n",
    "\n",
    "mean_diff = np.mean(treated_sample) - np.mean(control_sample)\n",
    "std_err_diff = np.sqrt(np.var(treated_sample, ddof=1)/len(treated_sample) + np.var(control_sample, ddof=1)/len(control_sample))\n",
    "\n",
    "# Confidence level and critical t-value\n",
    "confidence_level = 0.95\n",
    "t_crit = 1.96\n",
    "\n",
    "# Confidence interval\n",
    "CI_lower = mean_diff - t_crit * std_err_diff\n",
    "CI_upper = mean_diff + t_crit * std_err_diff\n",
    "\n",
    "print(f\"Confidence Interval: {CI_lower}, {CI_upper}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afacab61",
   "metadata": {},
   "source": [
    "In the t-test, we have $p \\approx 0.64 > \\alpha = 0.05$, so we cannot reject the null hypothesis, which is the same conclusion we draw from the Z-test. Also, $\\mu_0 = 0$ is contained in the confidence interval given by the t-text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72dfda2",
   "metadata": {},
   "source": [
    "### Type I and II Errors\n",
    "\n",
    "There are two types of error that can occur in hypothesis testing.\n",
    "A *type I* error is a false positive, i.e., rejecting a true null hypothesis.\n",
    "A *type II* error is a false negative, i.e., failing to reject a false null hypothesis.\n",
    "Both of these error types also occur outside of hypothesis testing.\n",
    "A type I error is sometimes called a *miscarriage of justice*, which is when someone is innocent but found guilty, while a type II error is called an *error of impunity*, since someone is guilty but found innocent.\n",
    "\n",
    "#### Table:\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-lboi{border-color:inherit;text-align:left;vertical-align:middle}\n",
    ".tg .tg-9wq8{border-color:inherit;text-align:center;vertical-align:middle}\n",
    ".tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky\" colspan=\"2\" rowspan=\"2\"></th>\n",
    "    <th class=\"tg-c3ow\" colspan=\"2\">Reality</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th class=\"tg-c3ow\">Positive</th>\n",
    "    <th class=\"tg-c3ow\">Negative</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-9wq8\" rowspan=\"2\">Study<br>findings</td>\n",
    "    <td class=\"tg-lboi\">Positive</td>\n",
    "    <td class=\"tg-0pky\">True Positive<br>(Power / Sensitivity)<br>1-&#946</td>\n",
    "    <td class=\"tg-0pky\">False Positive<br>Type I error<br>&#945</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-lboi\">Negative</td>\n",
    "    <td class=\"tg-0pky\">False Negative<br>Type II error<br>&#946</td>\n",
    "    <td class=\"tg-0pky\">True Negative<br>(Specifity)<br>1-&#945</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Depending on the scenario, we may have different tolerances for type I and type II errors.\n",
    "And ideally, we would like to minimize both of these errors, but there is a tradeoff between $\\alpha$, which is the probability of a type I error, and $\\beta$, which is the probability of a type II error.\n",
    "A summary of these values is given in Table 5.\n",
    "For modern hypothesis testing theory, tests are built to maximize power given our desired level of confidence, which is why we always pick $\\alpha$.\n",
    "\n",
    "A related notion is *power* or *sensitivity*, which is defined as $1 - \\beta$.\n",
    "By definition, this is the probability of rejecting the null hypothesis when the alternative hypothesis is true, i.e a true positive.\n",
    "As we mentioned before, we can perform a power analysis to determine the sample size necessary to correctly reject the null hypothesis assuming a given effect size.\n",
    "\n",
    "### Example\n",
    "\n",
    "In this example, we look at *return on investment (ROI)*, which is defined as\n",
    "$$\\text{ROI} = \\frac{\\gamma m - c}{c}$$\n",
    "where $\\gamma$ is the effect on sales, $m$ is the margin, and $c$ is the cost per person.\n",
    "Given a sample, we can estimate the effect on sales as the ATE, i.e $\\hat{\\gamma} = \\widehat{ATE}$.\n",
    "This also requires knowing the standard error of our estimated ATE, $\\text{SE}(\\widehat{ATE})$, which requires our sample size $n$, as well as the margin and the cost per person.\n",
    "\n",
    "One way to use this is to find the number of observations needed to test if we meet our target ROI.\n",
    "Note that\n",
    "\\begin{align*}\n",
    "\\text{SE}\\left(\\text{ROI}\\right) &= \\text{SE}\\left(\\frac{\\gamma m - c}{c}\\right) && \\text{definition of ROI} \\\\\n",
    "&= \\frac{m}{c}\\cdot\\text{SE}\\left(\\gamma\\right) && \\text{rules of variance} \\\\\n",
    "&= \\frac{m}{c}\\cdot\\frac{\\text{sd}(Sales)}{\\sqrt{n}} && \\text{definition of SE}\n",
    "\\end{align*}\n",
    "\n",
    "Suppose we think that $\\widehat{ATE} = \\$.35$ with $\\text{sd}\\left(\\widehat{Sales}\\right) = \\$75$.\n",
    "Moreover, we know that $c = .14$ and $m = .5$.\n",
    "How many observations do we need to show that ROI is significantly positive?\n",
    "Furthermore, assume that we also know that the true ROI is $25\\%$.\n",
    "For our lower bound at a $95\\%$ confidence level to be positive, which is equivalent to testing significance at $\\alpha = .05$, we have:\n",
    "\n",
    "\\begin{align*}\n",
    ".25 - 1.96\\cdot\\frac{.5}{.14}\\cdot\\frac{75}{\\sqrt{n}} > 0 &\\iff \\sqrt{n} > 1.96\\cdot\\frac{.5}{.14}\\cdot 75 \\cdot \\frac{1}{.25} \\\\\n",
    "&\\iff n > \\Big(1.96\\cdot\\frac{.5}{.14}\\cdot 75 \\frac{1}{.25}\\Big)^2 \\\\\n",
    "&\\iff n > 4,410,000\n",
    "\\end{align*}\n",
    "\n",
    "Here is the code using `Python`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "685010ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary sample size: 4409838.0\n"
     ]
    }
   ],
   "source": [
    "# what we're assuming\n",
    "sales_sd = 75\n",
    "c = 0.14\n",
    "m = 0.5\n",
    "roi = 0.25\n",
    "\n",
    "# # what levels we're testing\n",
    "alpha = 0.05\n",
    "z = norm.ppf(1 - alpha/2)\n",
    "\n",
    "# necessary n to reject the null\n",
    "n = np.ceil(((z * (m/c) * sales_sd) / roi)**2)\n",
    "\n",
    "print(f\"Necessary sample size: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6c769c",
   "metadata": {},
   "source": [
    "Then, with $n=4409838$ sample size, what is the power $(1-\\beta)$? In `Python`, `statsmodels.stats.power.TTestPower` can conviniently do a power analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caf41b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000441215462467"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.power import TTestPower\n",
    "\n",
    "roi_sd = (m/c) * sales_sd\n",
    "effect_size = roi / roi_sd\n",
    "\n",
    "TTestPower().power(effect_size = effect_size,\n",
    "                    nobs = n, alpha = alpha, alternative='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409e3ee",
   "metadata": {},
   "source": [
    "We still have about 50% probability to commit type II error, which we call a power of 50%. When designing experiments, a common rule is to get another observations to achieve predicted power of 80%. How many samples do we need to achieve, say, 80% power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94986dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Necessary sample size: 9010174.0\n"
     ]
    }
   ],
   "source": [
    "n = TTestPower().solve_power(effect_size = effect_size,\n",
    "                            nobs = None, alpha = alpha, power = 0.8, alternative='two-sided')\n",
    "\n",
    "print(f\"Necessary sample size: {np.ceil(n)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3874e9",
   "metadata": {},
   "source": [
    "## Forms of Randomization:\n",
    "\n",
    "There are several commonly used forms of randomization. The first one is called ''simple'' randomization. For this randomization, the assignment of a unit to the treatment and control is determined independently. For example, if one wants to treat 50% of the sample, one can flip a coin and if it is heads then the treatment is assigned. This form of randomization but does not exactly achieve the desired treatment probabilities. Just by chance, more or less than 50% of people may be assigned to the treatment.\n",
    "\n",
    "The next form of randomization is ''complete'' randomization. Under complete randomization, one has a target number of treated units and exactly those units are randomized to treatment. This can be done, for example, by assigning each unit a random normal draw, and giving the treatment to the top N units based on the random draw. Complete randomization is especially useful when you have a limited number of treatments to assign due to a budget constraint, or when the sample size is small.\n",
    "\n",
    "Another type of randomization is called blocking. Using the above two forms of randomization, one can by chance have imbalanace in covariates between treatment and control. For example, the treatment may have more men then women. Blocking eliminates this risk by completely randomizing within subgroups of the population. For example, if one wants to assign 10 out of 20 units to treatment. Then blocking would randomly select 5 men and randomly select 5 women to treatment. This would be called blocking on gender. Generally, the best variables to block on are ones that predict the outcome and for which imbalance could be a substantial problem. Blocking is an attempt to control this unwanted variability, which increases precision.\n",
    "\n",
    "Another form of randomization is *cluster randomization*, whereby treatment is assigned at a group level.\n",
    "For example, if treatment is a different teaching style, then necessarily entire classes are given the treatment at the same time.\n",
    "Likewise for ad campaigns or product pricing.\n",
    "Clustered random designs introduce dependency between the individuals within a cluster, which violates our independence assumption.\n",
    "This needs to be taken into account in a regression, and generally results in lower power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dccfe28",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Regression is a foundational method in statistics that relates to many other topics.\n",
    "In particular, linear regression, which we focus on here, is often taught as its own course.\n",
    "For this reason, we provide only a brief overview, but there are many excellent resources that explore the depth of this topic.\n",
    "\n",
    "### Overview\n",
    "\n",
    "Linear regression is a model that assumes a linear relationship between the dependent and independent variables.\n",
    "We say that\n",
    "\n",
    "\\begin{align*}\n",
    "Y &= \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_pX_p + \\varepsilon \\\\\n",
    "&= \\beta_0 + \\sum_{i=1}^p \\beta_pX_p + \\varepsilon \\\\\n",
    "&= X\\beta + \\varepsilon\n",
    "\\end{align*}\n",
    "where $Y$ is the dependent variable or *response*, $X_1, \\ldots, X_p$ are the independent or explanatory or predictor variables or *covariates*, $\\beta_1, \\ldots, \\beta_p$ are the corresponding (regression) *coefficients*, $\\beta_0$ is the *intercept* term, and $\\varepsilon$ is the *noise*.\n",
    "The noise, $\\varepsilon$, is taken to be mean zero, and represents the deviations from perfect linearity, which could be an artifact of imprecise measurements, or more likely that the \"true\" relationship is being approximated linearly.\n",
    "\n",
    "Given data $(X_1, Y_1), \\ldots, (X_n, Y_n)$, our goal is to estimate the coefficients.\n",
    "To do this, we use the method of ordinary least squares:\n",
    "$$\\hat{\\beta}_{OLS} = \\underset{\\tilde{\\beta}}{\\arg\\min} \\sum_{i=1}^n (Y_i - \\hat{Y}_i)^2$$\n",
    "where $\\hat{Y}_i = \\tilde{\\beta}_0 + \\sum_{i=1}^n X_i\\tilde{\\beta}_i$.\n",
    "This can be solved using calculus yielding the following closed-form solution:\n",
    "$$\\hat{\\beta}_{OLS} = (X^TX)^{-1}X^TY$$\n",
    "Under certain distributional assumptions, this solution is the same as the maximum likelihood estimate.\n",
    "\n",
    "In linear regression, we make several assumptions but the following ones are most relevant for this class:\n",
    "\n",
    "1. The response is a linear combination of the covariates and their regression coefficients.\n",
    "2. There is no multicollinearity between the predictors.\n",
    "3. If we want a causal interpretation of a coefficient on a variable x, the variable x should be independent of the error term. This would be violated in the case of selection bias.\n",
    "\n",
    "These assumptions should be checked via diagnostic tools whenever possible.\n",
    "\n",
    "There are two main uses of linear regression.\n",
    "The first major use is inference.\n",
    "Regression is very interpretable, so we can easily understand the relationships between the dependent and independent variables.\n",
    "Moreover, we can use the regression setting to test if linear relationships exist (are they significant?) and if so, what are their effects (what is the magnitude of the estimated coefficient?). If we make the assumption of errors being independent of the covariaties, then we can interpret the coefficients in the regression as being causal.\n",
    "\n",
    "The second major use is prediction.\n",
    "We can use the regression coefficients to predict what the response would be given a certain set of covariates.\n",
    "Next, we will discuss use cases specific to causal inference.\n",
    "\n",
    "### Log Transformations\n",
    "\n",
    "Critically, linear regression assumes a linear relationship between the response and the parameters.\n",
    "But what if we plot the data and the relationship is more complex?\n",
    "In some cases, we can use data transformations to recover linearity.\n",
    "One of the most popular such transformations is the logarithm.\n",
    "This is appropriate when the measurement of the response is on a logarithmic scale, which is multiplicative, rather than a linear scale.\n",
    "For example, the magnitude of earthquakes is measured with the Richter scale, which is logarithmic.\n",
    "\n",
    "In addition to transforming the response variable, it is also common to transform the covariates.\n",
    "(Ask yourself why this does not violate the linearity assumption.)\n",
    "Combinations of transformations of dependent and independent variables yield the following models:\n",
    "\n",
    "\\begin{align*}\n",
    "Y &= \\beta_0 + \\beta_1 X + \\varepsilon \\tag{$M_1$} \\\\\n",
    "\\log Y &= \\beta_0 + \\beta_1 X  + \\varepsilon \\tag{$M_2$} \\\\\n",
    "Y &= \\beta_0 + \\beta_1 \\log X + \\varepsilon \\tag{$M_3$} \\\\\n",
    "\\log Y &= \\beta_0 + \\beta_1 \\log X + \\varepsilon \\tag{$M_4$}\n",
    "\\end{align*}\n",
    "\n",
    "These models have the following different coefficient interpretations:\n",
    "\n",
    "- $(M_1)$ We expect a $\\beta_1$ increase in $Y$ for every unit increase in $X$\n",
    "- $(M_2)$ A unit increase in $X$ is expected to change $\\log Y$ by $\\beta_1$ or, equivalently, change $Y$ by $e^{\\beta_1}$ for natural log. An approximation is that a z unit change in X changes Y by $\\beta_{1} * z * 100$\\%.\n",
    "- $(M_3)$ $Y$ is expected to change by $\\beta_1 \\times \\frac{k}{100}$ for every $k$\\% increase in $X$.\n",
    "- $(M_4)$ On average, a k\\% change in X results in a $k \\times \\beta_{1}$\\% change in Y.\n",
    "\n",
    "\n",
    "### Interactions\n",
    "\n",
    "We might wonder or expect that there is an *interactive* effect between two variables.\n",
    "For example, suppose we have two binary covariates $x_1$ and $x_2$.\n",
    "We could use the following model with an interaction $x_1x_2$:\n",
    "$$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2 + \\varepsilon$$\n",
    "In this case, it is easy to interpret the coefficients simply by checking the combinations of $x_1$ and $x_2$:\n",
    "$$y = \\begin{cases}\n",
    "\\beta_0 + \\varepsilon & \\text{ if } x_1 = x_2 = 0 \\\\\n",
    "\\beta_0 + \\beta_1 + \\varepsilon & \\text{ if } x_1 = 1 \\text{ and } x_2 = 0 \\\\\n",
    "\\beta_0 + \\beta_2 + \\varepsilon & \\text{ if } x_1 = 0 \\text{ and } x_2 = 1 \\\\\n",
    "\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3 + \\varepsilon & \\text{ if } x_1 = x_2 = 1\n",
    "\\end{cases}$$\n",
    "Note that this is a saturated model, since there are as many parameters as variables, i.e\n",
    "$$\\widehat{\\beta_0} = \\frac{1}{\\sum_{i=1}^n I(x_{i1} = x_{i2} = 0)}\\sum_{i=1}^n y_i \\cdot I(x_{i1} = x_{i2} = 0)$$\n",
    "where $I(x_{i1} = x_{i2} = 0)$ is the indicator that subject $i$ has $x_1 = x_2 = 0$. If all of the variables are binary, then the predicted value of is just the mean of y (the outcome) for that combination of variables. \n",
    "\n",
    "In `Python`, we use the module [`PyFixest`](https://s3alfisc.github.io/pyfixest/tutorial/) and especially `pyfixest.estimation.feols`, in which an interaction can be included using the formula `y ~ x1 + x2 + x1:x2`.\n",
    "Equivalently, you can use `y ~ x1 * x2`, which automatically includes the main effect terms. Alternatively, one can also use `statsmodels.api.OLS.from_formula`.\n",
    "\n",
    "### Applications to Causal Inference\n",
    "\n",
    "The first thing we can do with regression is estimate the ATE.\n",
    "If we just want to see the relationship of the treatment on the outcome, then using regression will produce the same estimates as taking the difference of means.\n",
    "However, regression has the advantage of being able to incorporate any covariates, which is necessary for observational studies, but also useful for randomized trials if the covariates are imbalanced by chance and small sample size.\n",
    "\n",
    "Along those lines, we can also use regression to perform randomization tests (alternatively called balance checks).\n",
    "It is impossible for the treatment to affect anything before the experiment, and we can use this temporal argument to test whether the experiment was implemented properly.\n",
    "For example, the treatment should not affect demographics such as sex, race, or gender.\n",
    "If we run regress one of these *fixed* values on the treatment and find the regression coefficient for the treatment is significant, then there may be a problem.\n",
    "The most likely explanation is that the covariates are imbalanced.\n",
    "\n",
    "In an experiment, if the sample is large enough, then the covariates should be balanced between treatment and control so that the only difference in outcome is due to the treatment.\n",
    "This is the crux of randomization. However, we may have sampling constraints or want to ensure that certain covariates are balanced, which could lead us to sampling schemes other than simple random sampling.\n",
    "\n",
    "### Example\n",
    "\n",
    "Here, we present sample `Python` code for running a regression, performing diagnostics, and interpreting the output.\n",
    "First, we consider the linear relationship $Y = \\beta_0 + X\\beta_1 + \\varepsilon$, where $\\beta_0 = 3, \\ \\beta_1 = 2$, and $\\varepsilon \\sim \\mathcal{N}(0, 100)$.\n",
    "The module [`Seaborn`](https://seaborn.pydata.org/index.html) has a convinient plotting function `lmplot` for linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3569709d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fac872c8850>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(472)  # set seed for reproducible results\n",
    "\n",
    "n = 50\n",
    "X = np.arange(1, n + 1)\n",
    "eps = np.random.normal(scale=10, size=n)  # sample X_1, ..., X_50 ~ Z = N(0, 100)\n",
    "Y = 3 + 2*X + eps  # beta_0 = 3 and beta_1 = 2\n",
    "df = pd.DataFrame({'X': X, 'Y': Y})\n",
    "\n",
    "sns.lmplot(data = df, x='X', y='Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c89dc2",
   "metadata": {},
   "source": [
    "We can see the relationship is linear, but not perfectly (no line passes through every point).\n",
    "We can use linear regression to find the *line of best fit*, which is the one plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a1f0598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"2Q47Bl\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.2.0/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"2Q47Bl\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"2Q47Bl\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "\n",
      "Estimation:  OLS\n",
      "Dep. var.: Y\n",
      "Inference:  iid\n",
      "Observations:  50\n",
      "\n",
      "| Coefficient   |   Estimate |   Std. Error |   t value |   Pr(>|t|) |   2.5 % |   97.5 % |\n",
      "|:--------------|-----------:|-------------:|----------:|-----------:|--------:|---------:|\n",
      "| Intercept     |      2.202 |        2.734 |     0.805 |      0.425 |  -3.295 |    7.699 |\n",
      "| X             |      2.007 |        0.093 |    21.508 |      0.000 |   1.819 |    2.194 |\n",
      "---\n",
      "RMSE: 9.328   R2: 0.906\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Install pyfixest\n",
    "# !pip install pyfixest\n",
    "\n",
    "## The following two lines are used to force Jupyter display all outputs.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "from pyfixest.estimation import feols\n",
    "\n",
    "model = feols(\"Y~X\", data = df)\n",
    "\n",
    "## use model.coef() and model.confint() to extract estimates and 95% confidence intervals\n",
    "\n",
    "result = pd.DataFrame(model.coef()).reset_index()\n",
    "result.merge(model.confint().reset_index(), on = 'Coefficient')\n",
    "\n",
    "print(model.summary()) # full summary of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147457a",
   "metadata": {},
   "source": [
    "Alternatively, here's how we apply regressions using `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8185007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimates are \n",
      "Intercept    2.201840\n",
      "X            2.006754\n",
      "dtype: float64\n",
      "The standard errors are \n",
      "Intercept    2.733796\n",
      "X            0.093303\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td colspan=\"1\"><em>Dependent variable: Y</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>2.202<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.734)</td></tr>\n",
       "<tr><td style=\"text-align:left\">X</td><td>2.007<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.093)</td></tr>\n",
       "\n",
       "<td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>50</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.906</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.904</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>9.521 (df=48)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>462.590<sup>***</sup> (df=1; 48)</td></tr>\n",
       "<tr><td colspan=\"2\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"1\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x7fac78123c90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "lm = sm.OLS.from_formula(\"Y~X\", data = df)\n",
    "fit = lm.fit()\n",
    "\n",
    "print(f'The estimates are \\n{fit.params}')\n",
    "print(f'The standard errors are \\n{fit.bse}')\n",
    "#print(fit.summary())\n",
    "\n",
    "# Stargazer is a function that nicely formats regression results:\n",
    "Stargazer([fit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab1c36",
   "metadata": {},
   "source": [
    "We see that our estimates for $\\beta_0 = 3$ and $\\beta_1 = 2$ are $\\hat{\\beta}_1 = 2.007$, which is close, and $\\hat{\\beta}_0 = 2.202$, which is not.\n",
    "However, notice that the standard error for $\\hat{\\beta}_0$ is large, indicating that there is a lot of uncertainty around the estimate.\n",
    "In fact, the corresponding p-value (.425) is much greater than any reasonable $\\alpha$, so there is not much evidence for that estimate.\n",
    "On the other hand, the standard error for $\\hat{\\beta}_1$ is quite small, as is its corresponding p-value.\n",
    "And, as we should expect, the true value is captured in the 95% CI.\n",
    "Note that our estimates improve if we take larger $n$ or smaller variance for $\\varepsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb87e499",
   "metadata": {},
   "source": [
    "### Conditional Average Treatment Effects (CATE) and Interaction Effects\n",
    "We can also use regression to estimate conditional average treatment effects. A conditional average treatment effect given X is the average treatment effect for the subset of observations for which X is true. This can be estimated using an interaction regression. For example, suppose we want to measure the treatment effect conditional on X = 1. Let's simulate a dataset with a binary covairate X, a Treatment Y, and an interaction effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ea95167",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(472)  # set seed for reproducible results\n",
    "n = 50\n",
    "X = np.random.rand(n) > 0.5\n",
    "Treatment = np.random.rand(n) > 0.5\n",
    "eps = np.random.normal(scale=0.3, size=n)  # sample X_1, ..., X_50 ~ Z = N(0, 100)\n",
    "\n",
    "Y = 3 + 2 * X + 0.5 * Treatment + 0.2 * Treatment * X + eps  # beta_0 = 3 and beta_1 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449fbdf",
   "metadata": {},
   "source": [
    "We can calculate the CATE by simply taking the difference in means between the set of observations with X = 1 that are either treated or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5243af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4506508989816904"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATE = np.mean(Y[(X == 1) & (Treatment == 1)]) - np.mean(Y[(X == 1) & (Treatment == 0)])\n",
    "\n",
    "CATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfcaf05",
   "metadata": {},
   "source": [
    "Another way to do this is using a regression with an interaction effect and to add the coefficients on \"Treatment\" and \"X:Treatment\". Also note that the coefficeint on \"Treatment\" represents the treatment effect when X = 0 and the term \"(Intercept)\" is the mean of the outcome variable when X = 0 in the control group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "855df84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATE is 0.4506508989816913\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"text-align:center\"><tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td colspan=\"2\"><em>Dependent variable: Y</em></td></tr><tr><td style=\"text-align:left\"></td><tr><td style=\"text-align:left\"></td><td>(1)</td><td>(2)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "\n",
       "<tr><td style=\"text-align:left\">Intercept</td><td>2.202<sup></sup></td><td>3.043<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(2.734)</td><td>(0.090)</td></tr>\n",
       "<tr><td style=\"text-align:left\">Treatment[T.True]</td><td></td><td>0.324<sup>**</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.121)</td></tr>\n",
       "<tr><td style=\"text-align:left\">X</td><td>2.007<sup>***</sup></td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td>(0.093)</td><td></td></tr>\n",
       "<tr><td style=\"text-align:left\">X[T.True]</td><td></td><td>2.092<sup>***</sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.121)</td></tr>\n",
       "<tr><td style=\"text-align:left\">X[T.True]:Treatment[T.True]</td><td></td><td>0.126<sup></sup></td></tr>\n",
       "<tr><td style=\"text-align:left\"></td><td></td><td>(0.182)</td></tr>\n",
       "\n",
       "<td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr>\n",
       "<tr><td style=\"text-align: left\">Observations</td><td>50</td><td>50</td></tr><tr><td style=\"text-align: left\">R<sup>2</sup></td><td>0.906</td><td>0.925</td></tr><tr><td style=\"text-align: left\">Adjusted R<sup>2</sup></td><td>0.904</td><td>0.920</td></tr><tr><td style=\"text-align: left\">Residual Std. Error</td><td>9.521 (df=48)</td><td>0.312 (df=46)</td></tr><tr><td style=\"text-align: left\">F Statistic</td><td>462.590<sup>***</sup> (df=1; 48)</td><td>188.070<sup>***</sup> (df=3; 46)</td></tr>\n",
       "<tr><td colspan=\"3\" style=\"border-bottom: 1px solid black\"></td></tr><tr><td style=\"text-align: left\">Note:</td><td colspan=\"2\" style=\"text-align: right\"><sup>*</sup>p&lt;0.1; <sup>**</sup>p&lt;0.05; <sup>***</sup>p&lt;0.01</td></tr></table>"
      ],
      "text/plain": [
       "<stargazer.stargazer.Stargazer at 0x7fac7738d710>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = pd.DataFrame({'Y': Y, 'X': X, 'Treatment': Treatment})\n",
    "\n",
    "lm = sm.OLS.from_formula(\"Y ~ X * Treatment\", data = data)\n",
    "fit_inter = lm.fit()\n",
    "\n",
    "CATE = fit_inter.params['Treatment[T.True]'] + fit_inter.params['X[T.True]:Treatment[T.True]']\n",
    "print(f'CATE is {CATE}')\n",
    "\n",
    "# In the table below, we can compare the non-interacted model (1) and the interacted model (2).\n",
    "Stargazer([fit, fit_inter])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9811d010",
   "metadata": {},
   "source": [
    "## Non-Compliance\n",
    "\n",
    "Randomization is the hammer that can help us overcome selection bias.\n",
    "Until now, we have implicitly assumed that the treated and the control groups obey their assigned treatment status.\n",
    "We call anyone who receives the treatment when they are assigned the treatment group a *complier*.\n",
    "\n",
    "\n",
    "In some cases, we can directly ensure *compliance*, i.e treatment is taken by only and all of the treated group.\n",
    "For example, if we want to test the effect of caffeine on memorization tasks, then we can randomly assign caffeinated and decaffeinated coffee to two groups.\n",
    "Moreover, we can watch to make sure that all individuals drink the coffee they are given and do not drink any other coffee.\n",
    "\n",
    "\n",
    "Unfortunately, many experiments are not (and cannot be) designed so that researchers can monitor if treatment status is obeyed.\n",
    "Most of the time, non-compliance occurs when treatment is not taken by someone in the treated group rather than treatment being taken by someone in the control group.\n",
    "Such cases are common if treatment is taken at home and we need to carefully account for these cases.\n",
    "This practical component of causal inference is crucial to the success of our analyses.\n",
    "\n",
    "### Intention to Treat\n",
    "\n",
    "One simple approach to dealing with non-compliance is to measure the same quantity as ATE, but recognize that it is actually the *intent-to-treat effect* (ITT).\n",
    "The ITT is therefore the average effect of being placed in the treatment group.\n",
    "\n",
    "\n",
    "If we want to know the direct effect of the treatment, then obviously we would like to estimate ATE rather than ITT.\n",
    "However, it is important to recognize that sometimes we are actually interested in ITT.\n",
    "For example, if we want to understand the impact of a policy change such as free access to SAT preparatory classes, then ITT is more relevant than ATE.\n",
    "\n",
    "### Complier Average Causal Effects\n",
    "\n",
    "Instead of ITT, we can also calculate the *complier average causal effect* (CACE).\n",
    "The CACE is the average treatment effect among the compliers.\n",
    "If $T = \\mathbb{E}[Y(1)], \\ C = \\mathbb{E}[Y(0)]$, and $\\alpha$ is the *compliance rate*, then, assuming no effect on non-compliers, we can compute CACE as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "T - C &= \\alpha\\big(T_\\text{compliers} - C_\\text{compliers}\\big) + (1-\\alpha)\\big(T_\\text{non-compliers} - C_\\text{non-compliers}\\big) \\\\\n",
    "&= \\alpha\\big(T_\\text{compliers} - C_\\text{compliers}\\big)\n",
    "\\end{align*}\n",
    "where $T_\\text{non-compliers} = C_\\text{non-compliers}$ is a consequence of our assumption of no effect on non-compliers.\n",
    "Note that $T - C$ is just the ITT, or ATE if $\\alpha = 1$.\n",
    "Thus,\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "\\text{CACE} &= \\big(T_\\text{compliers} - C_\\text{compliers}\\big) \\\\\n",
    "& = \\frac{1}{\\alpha}(T - C) \\\\\n",
    "& = \\frac{ITT}{\\alpha}\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "\n",
    "One observation from the CACE formula is that\n",
    "$$\\text{SE}(CACE) = \\frac{\\text{SE}(ITT)}{\\alpha}$$\n",
    "Since $\\alpha \\in [0, 1]$, we will need a much larger sample size for estimating CACE.\n",
    "For example, if the compliance rate is $10\\%$, then the standard errors are 10 times larger and we would need 100 times the sample size to reduce the standard errors accordingly. \n",
    "\n",
    "\n",
    "Technical note: the standard error computed above is not exactly correct.\n",
    "If we want the correct standard error, we should use the `feols` function in `PyFixest` or conduct randomization inference.\n",
    "You do not have to know how to do this.\n",
    "\n",
    "Interpreting the above number as a CACE requires assumptions.\n",
    "The first of these assumptions is that not receiving the treatment does not have an effect.\n",
    "This would be violated in the following scenario.\n",
    "Suppose people assigned to the treatment group expected to get the treatment but did not.\n",
    "The assumption would be violated if this caused the people to become upset and to change their behavior as a result.\n",
    "\n",
    "Another important assumption is that the treatment increases the probability of receiving the treatment for everyone.\n",
    "This is by design in the voting example, but may be violated in other circumstances.\n",
    "\n",
    "We can avoid computing CACE by identifying the compliers, which can be done via *placebos*.\n",
    "A *placebo treatment* allows us to measure who would have complied.\n",
    "For example, in the example of calling people to increase voter turnout, the placebo is a public service announcement.\n",
    "The group that answers the phone call in the 'placebo' group would have been the compliers in the treatment group.\n",
    "Therefore, we can directly compare the compliers in the placebo group and the compliers in the treatment group to compute the CACE.\n",
    "This will give us more precise estimates when the compliance rate is low.\n",
    "\n",
    "However, there are no free lunches and use of a placebo is both expensive and subject to further assumptions.\n",
    "A key assumption is that the placebo treatment has no effect on the outcome.\n",
    "A second key assumption is that the likelihood of compliance is the same in the treatment and placebo groups.\n",
    "This assumption can be tested by looking at the realized compliance rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1bd65",
   "metadata": {},
   "source": [
    "## Observational Data\n",
    "\n",
    "Here, we discuss the difference-in-difference method for performing causal inference with observational data.\n",
    "\n",
    "### Difference in Differences\n",
    "\n",
    "In the early 1850s, a London doctor named John Snow went door to door to observe the presence of cholera.\n",
    "Additionally, he tabulated the water supply source for each household.\n",
    "His assumption was that \"there is no difference whatever in the houses or the people receiving the supply of the two Water Companies, or in any of the physical conditions with which they are surrounded.\"\n",
    "Therefore, Snow was able to compare cholera status in two groups that were similar except for their treatment.\n",
    "In doing so, he was able to determine a causal link between water source and cholera being the first to establish cholera as a water-borne disease.\n",
    "\n",
    "The crucial step in this analysis is that if two groups are similar except for treatment, then any differences in outcomes between the groups is due to the treatment.\n",
    "This methodology is known as *difference in differences* (DID).\n",
    "If $Y_{it}$ is our response for group $i$ at time $t$, then the difference in differences is calculated as\n",
    "$$DID = \\left(Y_{1, \\ \\text{post}} - Y_{0, \\ \\text{post}}\\right) - \\left(Y_{1, \\ \\text{pre}} - Y_{0, \\ \\text{pre}}\\right)$$\n",
    "\n",
    "\n",
    "One important assumption for the difference in differences method is the *assumption of parallel trends*, which says that without treatment, the difference between the treatment and control group is constant over time.\n",
    "This assumption cannot be tested statistically, but it is important to visualize the relationship if observations are available over time.\n",
    "In particular, you want to see that the pre-intervention relationship between treatment and control group is in lockstep, i.e any deviations only occur post-intervention.\n",
    "\n",
    "\n",
    "We can use simple algebra to demonstrate why the difference in differences estimator works.\n",
    "Consider the setting of brand keyword advertising in search engines.\n",
    "Suppose that Ebay turns off its ads on Bing but keeps them on Google.\n",
    "Furthermore, suppose that the log of clicks can be expressed as follows:\n",
    "$$E[Y_{it}] = \\gamma_{i} + \\lambda_{t} + \\delta T_{it}$$\n",
    "or in words:\n",
    "$$E[\\text{Log}(\\text{Clicks for Search Engine $i$ in time period $t$})] = \\gamma_{i} + \\lambda_{t} + \\delta T_{it}$$\n",
    "\n",
    "Suppose there are two periods (before and after), then we can show that the simple difference in differences results in an unbiased estimate of $\\delta$, the treatment effect. \n",
    "\\begin{align*}\n",
    "&E[Y_{\\text{Bing, After}} - Y_{\\text{Google, After}}] - E[Y_{\\text{Bing, Before}} - Y_{\\text{Google, Before}}]\\\\\n",
    "=& (\\gamma_{\\text{Bing}} + \\lambda_{\\text{After}} + \\delta - \\gamma_{\\text{Google}} - \\lambda_{\\text{After}}) - (\\gamma_{\\text{Bing}} + \\lambda_{\\text{Before}} - \\gamma_{\\text{Google}} - \\lambda_{\\text{Before}})\\\\\n",
    "=&(\\gamma_{\\text{Bing}} + \\delta - \\gamma_{\\text{Google}}) - (\\gamma_{\\text{Bing}} - \\gamma_{\\text{Google}}) = \\delta.\n",
    "\\end{align*}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
